{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Theory\n",
    "Decision theory is about finding \"optimal\" actions, under various definitions of optimality.\n",
    "\n",
    "\n",
    "## Typical Sequence of Events\n",
    "* Many problem domains can be formalized as follows:\n",
    "  * Observe input $x$\n",
    "  * Take action $a$\n",
    "  * Observe outcome $y$\n",
    "    * Outcome $y$ is often **independent** of action $a$\n",
    "    * But this is **not always the case**:\n",
    "      * search result ranking\n",
    "      * automated driving\n",
    "      * stock market predicitons from analysts might affect market movement\n",
    "  * Evaluate action in relation to the outcome: $L(a,y)$\n",
    "  \n",
    "## The Three Spaces\n",
    "* Input space: $\\mathcal X$\n",
    "* Action spcae: $\\mathcal A$\n",
    "* Outcome space: $\\mathcal Y$\n",
    "\n",
    "### Action\n",
    "* Definition: An action is the generic term for what is produced by our system (my understanding the system here means prediction function)\n",
    "\n",
    "* Examples of Actions\n",
    "  * Produce a $0/1$ classification [classical ML]\n",
    "  * Reject hypothesis that $\\theta = 0$ [classical Statistics]\n",
    "  * Written English text [image captioning, speech recognition, machine translation]\n",
    "  \n",
    "### Decision Function\n",
    "Definition: A **decision function (or **predicition function**) gets input $x \\in \\mathcal{X}$ and produces an action $a \\in \\mathcal {A}$:\n",
    "\n",
    "\\begin{equation}\n",
    "f: \\mathcal{X} \\to \\mathcal{A}\\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "x \\to f(x)\n",
    "\\end{equation}\n",
    "\n",
    "### Loss Function\n",
    "Definition: A **loss function** evaluates an action in the context of the outcome $y$:\n",
    "\n",
    "\\begin{equation}\n",
    "L: \\mathcal {A} \\times \\mathcal{Y} \\to \\mathbb{R} \\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "(a,y) \\to L(a,y)\n",
    "\\end{equation}\n",
    "\n",
    "## Formalizing a \"Data Science\" Problem\n",
    "1. First two steps to formalizing a problem  \n",
    "  1. Define the *action space* (i.e. the set of possible actions)\n",
    "  1. Specify the evaluation criterion.\n",
    "1. When a \"stakeholder\" asks the data scientist to solve a problem, she\n",
    "  1. may have an opinion on what the action space should be, and\n",
    "  1. hopefully has an opinion on the evaluation criterion, but\n",
    "  1. she really cares about your **producing a \"good\" decision function**.\n",
    "1. Typical sequence:\n",
    "  1. Stakeholder presents problem to data scientist\n",
    "  1. Data scientist produces decision function.\n",
    "  1. Engineer deploys \"industrial strength\" version of decision function.\n",
    "\n",
    "## Evaluating a Decision Function\n",
    "* Loss function $L$ only evaluates a single action\n",
    "* How to evaluate the decision function as a whole? (Answer: Statistical Learning Theory)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning Theory\n",
    "\n",
    "## A Simplifying Assumption\n",
    "* Assume action has no effect on the output\n",
    "* Assume there is a data generating distribution $\\mathcal{P}_{\\mathcal{X}\\times\\mathcal{Y}}$.\n",
    "* All input/output pairs $(x,y)$ are generated i.i.d. from $\\mathcal{P}_{\\mathcal{X}\\times\\mathcal{Y}}$.\n",
    "  * no covariate shift\n",
    "  * no concept drift\n",
    "* Want decision function $f(x)$ that generally \"does well on average\":\n",
    "\\begin{equation}\n",
    "L(f(x), y) \\;\\;\\;\\text{ is usually small, in some sense}\n",
    "\\end{equation}\n",
    "\n",
    "## Risk of a Decision Function\n",
    "Definition: Given a decision function (or prediction function) $f(x): \\mathcal{X} \\to \\mathcal{A}$, the **risk** of this decision funciton is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "R(f) = E[L(f(x), y)]\n",
    "\\end{equation}\n",
    "\n",
    "where $L(f(x), y)$ is the **loss function**.\n",
    "\n",
    "In words, it's the **expected loss** of $f$ on a new example $(x,y)$ drawn randomly from $\\mathcal{P}_{\\mathcal{X}\\times\\mathcal{Y}}$.\n",
    "\n",
    "* We usually don't know $\\mathcal{P}_{\\mathcal{X}\\times\\mathcal{Y}}$, so we cannot compute the expectation. But we can estimate it.\n",
    "\n",
    "### The Bayes Decision Function\n",
    "Definition: A **Bayes decision function** $f^* : \\mathcal{X} \\to \\mathcal{A}$ is a function that achieves the *minimal risk* among all possible functions:\n",
    "\n",
    "\\begin{equation}\n",
    "f^* = argmin_f{R(f)}\n",
    "\\end{equation}\n",
    "\n",
    "where the minimum is taken over all functions from $\\mathcal{X}$ to $\\mathcal{A}$.\n",
    "\n",
    "* The risk of a Bayes decision function is called the **Bayes Risk**.\n",
    "  * There can be multiple Bayes decision functions that achieve the same minimal risk.\n",
    "* A Bayes decision function is often called the **target function**, since it's the best decision function we can possibly produce.\n",
    "\n",
    "\n",
    "## The Empirical Risk Functional\n",
    "### The Empirical Risk of a Decision Function\n",
    "Let $\\mathcal{D}_n=((x_1,y_1),\\dots,(x_n,y_n))$ be drawn i.i.d. from $\\mathcal{P}_{\\mathcal{X}\\times\\mathcal{Y}}$.\n",
    "\n",
    "Definition: The **empirical risk** of $f:\\mathcal{X}\\to \\mathcal{A}$ with respect to $\\mathcal{D}_n$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{R}_n(f) = \\frac{1}{n}\\sum_{i=1}^{n}L(f(x_i),y_i)\n",
    "\\end{equation}\n",
    "\n",
    "By the Strong Law of Large Numbers,\n",
    "\n",
    "\\begin{equation}\n",
    "\\lim_{n\\to \\infty}\\hat{R}_n(f)=R(f) \\;\\;\\;\\text{ almost surely.}\n",
    "\\end{equation}\n",
    "\n",
    "### Empirical Risk Minimization (ERM)\n",
    "Definition: A function $\\hat{f}$ is an **empirical risk minimizer** if \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f} = argmin_f{\\hat{R}_n(f)}\n",
    "\\end{equation}\n",
    "\n",
    "where the minimum is takend over all function.\n",
    "\n",
    "\n",
    "### Constrained Empirical Risk Minimization (CERM)\n",
    "* ERM led to a function $f$ that just memorized the data, ERM can lead to overfitting.\n",
    "* How to spread information or \"generalize\" from training inputs to new inputs?\n",
    "* Need to smooth things out somehow...\n",
    "  * A lot of modeling is about spreading and extrapolating information from one part of the input space $\\mathcal{X}$ into unobserved parts of the space.\n",
    "* One approach: \"Constrained ERM\"\n",
    "  * Instead of minimizing empirical risk over all decision functions,\n",
    "  * constrain to a particular subset, called a **hypothesis space**.\n",
    "* The restrictions are called an *inductive bias*\n",
    "* A fundamental question in learning theory is, over which hypothesis classes ERM learning will not result in overfitting.\n",
    "\n",
    "#### Hypothesis Spaces \n",
    "Definition: A **hypothesis space** $\\mathcal{F}$ is a set of [decision ] functions mapping $\\mathcal{X} \\to \\mathcal{A}$. It is the collection of decision functions we are considering.\n",
    "\n",
    "#### CERM\n",
    "* **Empirical Risk Minimizer** (ERM) in $\\mathcal{F}$ is\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}_n = argmin_{f\\in \\mathcal{F}}\\frac{1}{n}\\sum_{i=1}^{n}{L(f(x_i),y_i)}\n",
    "\\end{equation}\n",
    "\n",
    "* **Risk minimizer** in $\\mathcal{F}$ is $f^*_{\\mathcal{F}} \\in \\mathcal{F}$, where\n",
    "\n",
    "\\begin{equation}\n",
    "f^*_{\\mathcal{F}} = argmin_{f\\in \\mathcal{F}}E[L(f(x),y)]\n",
    "\\end{equation}\n",
    "\n",
    "### Procedure of ERM\n",
    "* Given a loss function $L:\\mathcal{A}\\times \\mathcal{Y} \\to \\mathbb{R}$\n",
    "* Choose hypothesis space $\\mathcal{F}$\n",
    "* Use an optimization method to find ERM $\\hat{f}_n \\in \\mathcal{F}$\n",
    "  \n",
    "\\begin{equation}\n",
    "\\hat{f}_n=argmin_{f\\in \\mathcal{F}}\\frac{1}{n}\\sum_{i=1}^{n}{L(f(x_i),y_i)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "## Excess Risk Decomposition\n",
    "\n",
    "### Error Decomposition\n",
    "\n",
    "Consider following decision functions\n",
    "\n",
    "* Risk minimizer (i.e. Bayes decision function) over all functions\n",
    "\n",
    "\\begin{equation}\n",
    "f^{*}=argmin_{f} E[L(f(X),Y)]\n",
    "\\end{equation}\n",
    "\n",
    "* Risk minimizer over all functions within hypothesis space $\\mathcal{F}$\n",
    "\n",
    "\\begin{equation}\n",
    "f_{\\mathcal{F}} = argmin_{f\\in \\mathcal{F}} E[L(f(X),Y)]\n",
    "\\end{equation}\n",
    "\n",
    "* Empirical Risk minimizer over all functions within hypothesis space $\\mathcal{F}$\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}_n = argmin_{f\\in \\mathcal{F}}\\frac{1}{n}\\sum_{i=1}^{n}{L(f(x_i),y_i)}\n",
    "\\end{equation}\n",
    "\n",
    "![Risk Error Decomposition](resources/risk_error_decomposition.gif)\n",
    "\n",
    "### Approximation Error (of $\\mathcal{F}$)  =  $R(f_{\\mathcal{F}}) - R(f^*)$\n",
    "* Approximation error is a property of the class $\\mathcal{F}$\n",
    "* It is the penalty for restricting to $\\mathcal{F}$ (rather than consdering all possible functions)\n",
    "* Bigger $\\mathcal{F}$ means smaller approximation error.\n",
    "* Approximation error is a non-random variable.\n",
    "\n",
    "### Estimation Error (of $\\hat{f}_n\\;in\\; \\mathcal{F}$)  =  $R(\\hat{f}_n) - R(f_{\\mathcal{F}})$\n",
    "* Note, $R(\\hat{f}_n) = E[L(\\hat{f}_n(X),Y)]$. \n",
    "* Estimation error is a random variable since the data, $(x_i,y_i), i = 1, 2, \\dots, n$, used to compute  $\\hat{f}_n$, i.e. $argmin_{f\\in \\mathcal{F}}\\frac{1}{n}\\sum_{i=1}^{n}{L(f(x_i),y_i)}$, is randomly sampled from distribution $\\mathcal{P}_{\\mathcal{X}\\times\\mathcal{Y}}$. So the risk $R(\\hat{f}_n)$ depends on training data.\n",
    "* Estimation error is the performance hit for choosing $f$ using finite training data\n",
    "* It is the performance hit for minimizing empirical risk rather than true risk\n",
    "* With smaller $\\mathcal{F}$ we expect smaller estimation error. \n",
    "* Under typical conditions: \"With infinite training data, estimation error goes to zero\"\n",
    "\n",
    "### Optimization Error\n",
    "* In practice of ERM, we don't find the empirical risk minimizer $\\hat{f}_n \\in \\mathcal{F}$\n",
    "  * For nice choices of loss functions and classes $\\mathcal{F}$, we can get arbitrarily close to a empirical risk minimizer, but that takes time, is it worth it?\n",
    "  * For some hypothesis spaces (e.g. neural networks), we don't know how to find $\\hat{f}_n \\in \\mathcal{F}$\n",
    "* In stead, in practice, we find $\\tilde{f}_n \\in \\mathcal{F}$ that we hope is good enough\n",
    "\n",
    "Definition: If $\\tilde{f}_n$ is the function our optimization method returns, and $\\hat{f}_n$ is the empirical risk minimizer, then \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Optimization Error } = R(\\tilde{f}_n) - R(\\hat{f}_n)\n",
    "\\end{equation}\n",
    "\n",
    "* Note: optimization error can be negative. \n",
    "* But by definition of $\\hat{f}_n$, in empirical risk we have\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{R}(\\tilde{f}_n) - \\hat{R}(\\hat{f}_n) \\ge 0\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### Excess Risk\n",
    "Definition: The **excess risk** compares the risk of $f$ to the Bayes optimal $f^*$\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Excess Risk}(f)=R(f) - R(f^*)\n",
    "\\end{equation}\n",
    "\n",
    "Note: excess risk can never be negative.\n",
    "\n",
    "### Excess Risk Decomposition for ERM\n",
    "#### The excess risk of the ERM $\\hat{f}_n$ can be decomposed\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Excess Risk}(\\hat{f}_n) = R(\\hat{f}_n)-R(f^*)= [R(\\hat{f}_n)-R(f_{\\mathcal{F}})] + [R(f_{\\mathcal{F}}) - R(f^*)]= \\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{                                                           Estimation Error } + \\text{        Approximation Error}\n",
    "\\end{equation}\n",
    "\n",
    "* Data scientist's job\n",
    "  * choose $\\mathcal{F}$ to balance between approximation and estimation error\n",
    "  * as we get more training data, use a bigger $\\mathcal{F}$.\n",
    "  \n",
    "#### The excess risk for function $\\tilde{f}_n$ can be decomposed  \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Excess Risk}(\\tilde{f}_n) = R(\\tilde{f}_n)-R(f^*)= \\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "[R(\\tilde{f}_n)-R(\\hat{f}_n)] + [R(\\hat{f}_n)-R(f_{\\mathcal{F}})] + [R(f_{\\mathcal{F}}) - R(f^*)]= \\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{  Optimization Error} + \\text{ Estimation Error } + \\text{        Approximation Error}\n",
    "\\end{equation}\n",
    "\n",
    "### Function Approximation and Estimation\n",
    "\n",
    "* The goal is to obtain a useful approximation to $f(x)$ for all $x$ in some region of $\\mathbb{R}^p$, which is the input space, given the representations in the training data, $T$.\n",
    "* This is compared with 'learning by example' paradigm.\n",
    "* ESL Approach: Treating supervised learning as a problem in function approximation and estimation encourages the geometrical concepts of Euclidean spaces and mathematical concepts of probablistic inference to be applied to the problem.\n",
    "\n",
    "\n",
    "# Applications\n",
    "\n",
    "## Regression Function\n",
    "\n",
    "### Squared Error Loss\n",
    "Let $X \\in R^p$ denote a real valued random input vector, and $Y \\in R$ a real valued random output variable, with joint distribution $P(X,Y)$. We seek a function $f(X)$ for predicting $Y$ given values of the input $X$.\n",
    "\n",
    "Consider the **squared error loss** function, where $L(f(x), y) = (y-f(x))^2$. We have the risk or **Expected Prediction Error (EPE in ESL)** as:\n",
    "\n",
    "\\begin{equation}\n",
    "R(f) = E[(Y-f(X))^2] = \\int [y-f(x)]^2P(x,y)\n",
    "\\end{equation}\n",
    "\n",
    "By conditioning on $X$, we can write the risk as\n",
    "\n",
    "\\begin{equation}\n",
    "R(f) = E_XE_{Y|X}[(Y-f(X))^2|X]\n",
    "\\end{equation}\n",
    "\n",
    "We see that it suffices to minimize the risk $R(f)$ pointwise:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = argmin_cE_{Y|X}[(Y-c)^2|X]\n",
    "\\end{equation}\n",
    "\n",
    "The solution is the target function or Bayes decision function:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = E[Y|X=x]\n",
    "\\end{equation}\n",
    "\n",
    "The conditional expectation is also known as the **regression function**. Thus the best prediction of $Y$ at any point $X=x$ is the conditional mean, when best is measured by average squared error.\n",
    "\n",
    "### $L_1$ Loss\n",
    "\n",
    "The loss function is: $L_1: E|Y-f(X)|$. The Bayes function in this case is the conditional median\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x) = \\text{median}(Y|X=x)\n",
    "\\end{equation}\n",
    "\n",
    "Its estimate are more robust than those for the conditional mean. \n",
    "\n",
    "## Classification Function with 0-1 Loss\n",
    "* The loss function is 0-1 loss.\n",
    "* The Bayes Function or *Bayes classifier* is found to be\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = argmin_{g \\in \\mathcal{G}} [1-P(Y=g|X=x)]\\; \\text{ or simply} \\\\\n",
    "f(x) = \\mathcal{G}_k \\; if \\; P(Y=g_k|X=x) = max_{g \\in \\mathcal{G}} P(Y=g|X=x)\n",
    "\\end{equation}\n",
    "\n",
    "The error rate of the Bayes classifier is called the Bayes rate (i.e. Bayes Risk).\n",
    "\n",
    "The Bayes classifier says that we classify to the most probable class, using the conditional (discrete) distribution $P(Y|X)$.\n",
    "\n",
    "### Connection with the Bayes function for Regression Problem\n",
    "Suppose we have a two-class problem and use the dummy-variable approach, followed by squared error loss estimation. Then\n",
    "\n",
    "\\begin{equation}\n",
    "f(X)=E(Y|X)=P(Y=g_1|X)\\; if\\; g_1 \\text{ corresponds to }\\; Y=1 \\\\\n",
    "\\end{equation}\n",
    "\n",
    "Likewise for a K-class problem\n",
    "\n",
    "\\begin{equation}\n",
    "E(Y_k|X) = P(Y=g_k|X)\n",
    "\\end{equation}\n",
    "\n",
    "This shows that our dummy-variable regression procedure, followed by classification to the largest fitted value, is another way of representing the Bayes classifier. \n",
    "\n",
    "### The Method of Least Squares\n",
    "\n",
    "\n",
    "* The hypothesis space is of linear models between output and its arguments\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f} = X^T \\hat{\\beta}\n",
    "\\end{equation}\n",
    "\n",
    "* The loss function is squared loss.\n",
    "* We then minimize the empirical risk without the $\\frac{1}{N}$ term, i.e.\n",
    "\n",
    "\\begin{equation}\n",
    "argmin_{\\beta} RSS(\\beta)=\\sum_{i=1}^{N}(y_i - x^T_i\\beta)^2\n",
    "\\end{equation}\n",
    "\n",
    "This is normally called **Residual Sum of Squares** in linear regression. \n",
    "\n",
    "The optimal value $\\hat{\\beta}$ shall give us the ERM, i.e. $\\hat{f} = X^T \\hat{\\beta}$.\n",
    "\n",
    "* The minimization can be done analytically. By differentiating w.r.t. $\\beta$, we obtain the *normal equations*:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{X}^T(\\mathbb{y} - \\mathbb{X}\\beta) = 0\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbb{X}$ is $N \\times p$, $\\mathbb{y}$ is an N-vector.\n",
    "\n",
    "If $\\mathbb{X}^T\\mathbb{X}$ is nonsingular, then the solution is unique, and it is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta} = (\\mathbb{X}^T \\mathbb{X})^{-1}\\mathbb{X}^T\\mathbb{y}.\n",
    "\\end{equation}\n",
    "\n",
    "* If we substitute the linear model into risk formula (i.e. EPE) and tries to find the Bayes decision function, we have\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta = [E(XX^T)]^{-1}E(XY)\n",
    "\\end{equation}\n",
    "\n",
    "* Compare this with the general Bayes decision function (without a linear hypothesis space assumption). \n",
    "  * We have not conditioned on $X$; rather we have used our knowledge of the functional relationship to pool over values of $X$. The least squares solution from ERM amounts to replace the expectation above by averages over the training data. \n",
    "\n",
    "### The Nearest-Neighbor Methods (KNN)\n",
    "\n",
    "* What's the hypothesis space for the nearest-neighbor method?\n",
    "  * Locally constant (or piecewise constant) functions with knots determined by training data. \n",
    "  * Can we have a hypothesis space that depends on $k$? \n",
    "    * Probably yes, the prediction function $f(x)$ can be a function of $N/k$ number of nonoverlap (a strong assumption?) regions (or $N/k-1$ number of knots). For example, when $k=1$, there'll be $N$ regions in the piecewise function. When $k=2$, there'll be $N/2$ regions for the function. The position of knots and the function values at the knots will be determined by empirical risk minimization procedure.\n",
    "    * It can be seen that the hypothesis space with $N$ regions is a super set of hypothesis space with $N/2$ regions because the latter can always be divided into half and keep the same values as before and we obtain a function in $N$ space. But we can't do it the other way around. This demonstrates that any function in hypothesis space $N/2$ is in space $N$. So we have: $\\mathcal{F}_{N} \\subseteq \\mathcal{F}_{N-1} \\subseteq \\dots \\mathcal{F}_i \\subseteq \\dots \\mathcal{F}_2 \\subseteq \\mathcal{F}_1$\n",
    "    \n",
    "    where the subscripts $i$ means the number of points used to compute the average, i.e. $k$.\n",
    "* What's the loss function ?\n",
    "  * 0-1 loss\n",
    "* Can we derive the ERM for nearest-neighbor method?\n",
    "  * Seems to be straight forward for $k=1$\n",
    "  * When $k>1$, if we can use the hypothesis space depends on $k$, it's easy to see that the ERM should be average. \n",
    "  \n",
    "* The prediction function for KNN is\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x)=\\frac{1}{k}\\sum_{x_i \\in N_k(x)} y_i\n",
    "\\end{equation}\n",
    "\n",
    "where $N_k(x)$ is the neighborhood of $x$ defined by the $k$ closest points $x_i$ in the training sample.\n",
    "\n",
    "* The error on the training data should be approximately an increasing function of $k$, and will always be $0$ for $k=1$.\n",
    "* The *effective* number of parameters of k-nearest neighbors is $N/k$ and is generally bigger than $p$ in least-squares fits, and decreases with increasing $k$.\n",
    "* The KNN attempts to approximate the Bayes decision function, i.e. $f(x)=E(Y|X=x)$ using the training data. The KNN is our $f_{\\mathcal{F}}$.\n",
    "  * Expectation is approximated by averaging over sample data.\n",
    "  * Conditioning at a point is relaxed to conditioning on some region \"close\" to the target point.\n",
    "* Under mild regularity conditions on the joint probability distribution $P(X,Y)$, one can show that as $N,k \\to \\infty$ such that $k/N \\to 0, \\hat{f}(x) \\to E(Y|X=x)$.\n",
    "* However\n",
    "  * We often do not have very large samples, Linear or other structured models can be more stable than KNN.\n",
    "  * As dimension $p$ gets large, so does the metric size of the k-nearest neighborhood. The convergence above still holds, but at the rate of convergence decrease as the dimension increases.\n",
    "  \n",
    "* If we compare the KNN with the Bayes classifier () for classification problem (derived above). We see that the KNN classifier directly approximates the Bayes classifier: a majority vote in a nearest neighborhood amounts to exactly this, except that conditional probability at a point is relaxed to conditional probability within a neighborhood of a point, and probabilities are estimated by training-sample proportions.  \n",
    "\n",
    "#### Curse of Dimensionality\n",
    "* If the dimension of the input space is high, the nearest neighbors need not be close to the target point, and can result in large errors.\n",
    "  * In high dimension, to have a neighborhood of a point $x$ to form a local average (say, 10% of total volume), the expected edge length (on each dimension) needs to increase a lot, e.g. 80%, in terms of total length in each dimension. (to a degree, such neighborhoods are no longer \"local\"). Reducing the neighborhood size causes higher variance of our fit.\n",
    "  * In high dimension, all sample points are close to an edge of the sample. Most data points are closer to the boundary of the sample space than to any other data point. Prediction is much more difficult near the edges of the training sample. One must extrapolate from neighboring sample points rather than interpolate between them.\n",
    "  * In high dimension, the sampling density is proportional to $N^{1/p}$, where $p$ is the dimension of the input space and $N$ is the sample size. Thus all feasible training samples sparsely populate the input space. You need enormous amount of data to have a meaningful sampling density. \n",
    "\n",
    "* By imposing some heavy restrictions on the class of models being fitted, we can reduce both the bias and the variance of the estimates.\n",
    "  * The complexity of functions of many variables can grow exponentially with the dimension, and if we wish to be able to estimate such functions with the same accuracy as function in low dimensions, then we need the size of our training set to grow exponentially as well. \n",
    "\n",
    "\n",
    "### Relationships to Other Methods\n",
    "* Kernel methods use weights that decrease smoothly to zero with distance from the target point, rather than the effective $0/1$ weights used by k-nearest neighbors. \n",
    "* Local regression fits linear models by locally weighted least squares, rather than fitting constants locally.\n",
    "* Linear models fit to a basis expansion of the original inputs allow arbitrarily complex models.\n",
    "* Projection pursuit and neural network models consist of sums of non-linearly transformed linear models.\n",
    "\n",
    "### Additive Models\n",
    "* Additive Error Model\n",
    "\n",
    "\\begin{equation}\n",
    "Y=f(X)+\\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "Where the random error $\\epsilon$ has $E(\\epsilon)=0$ and is independent of $X$. The $f(X)$ is a deterministic function. For most systems the input-output pairs $(X,Y)$ will not have a deterministic relationship. The additive model assumes that we can capture all these departures from a deterministic relationship via the error $\\epsilon$.\n",
    "\n",
    "  * Many of the classification problems are of this form. The randomness enters through the $x$ location of the training points.\n",
    "  \n",
    "\n",
    "* The hypothesis space of additive models is:\n",
    "\n",
    "\\begin{equation}\n",
    "f(X) = \\sum_{j=1}^{p}f_j(X_j)\n",
    "\\end{equation}\n",
    "\n",
    "This retains the additivity of the linear model, but each coordinate function $f_j$ is arbitrary.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
