
## The complexity of $\mathcal{H}$
* The number of hypothesis functions $M$ can be thought of as a 'complexity' measure of the hypothesis set $\mathcal{H}$.
* If $M$ goes up, then $e_{in}(g)$ will be a poor estimator of $e_{out}(g)$ according to the inequality (hence helps question 1), however there'll be a better chance to get small $e_{in}(g)$ (hence hurts question 2).

## The complexity of the target function $f$
* The complexity of $f$ doesn't affect how well  $e_{in}(g)$ approximates  $e_{out}(g)$
* However, we'll get a worse  $e_{in}(g)$ when $f$ is complex.

* As long as we make sure that the complexity of $\mathcal{H}$ gives us a good Hoeffding bound, our success or failure in learning $f$ can be determined by our success or failure in fitting the training data.

# 1.4 Error and Noise
## 1.4.1 Error Measure
* An error measure quantifies how well each hypothesis function $h$ in the model approximates the target function $f$.
$Error = E(h,f)$.
* One may view $E(h,f)$ as the cost of using $h$ when you should use $f$.
* The choice of the error measure affects the outcome of learning process.
* The choice of the error measure depends on how the system is going to be used, rather than on any inherent criterion that we can independently determine during learning process.

## 1.4.2 Noise Target
* Instead of $y=f(X)$, we take the output $y$ to be a random variable that is affected by, rather than determined by, the input $X$.
Formally, we have a target distribution, $P(y|X)$ instead. A data point $(x,y)$ is now generated by the joint distribution $P(X,y) = P(X)P(y|X)$.
* One can think of a noise target $y$ as a deterministic target plus added noise. For example, take $f(X)=E[y|X]$, then $y = f(X) + noise$.
* $P(y|X)$ is what we are trying to learn, $P(X)$ only quantifies the relative importance of the point $X$ in gauging how well we have learned. 

* Note, the Hoeffding inequality applies to noise target as well because it applies to an arbitrary, unknown target function. Assume we randomly pick all the $y$'s according to the distribution $P(y|X)$ over the entire input space $\mathcal{X}$. This realization of $P(y|X)$ is effectively a target function. Therefore the inequality will be valid no matter which particular random realization the 'target function' happens to be.
