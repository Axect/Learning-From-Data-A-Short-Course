{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1\n",
    "\n",
    "No. PLA will keep updating if the data is not linearly separable.\n",
    "\n",
    "#### Exercise 3.2 TODO\n",
    "\n",
    "#### Exercise 3.3\n",
    "\n",
    "1. (a) $H$ is symmetric.\n",
    "\n",
    "\\begin{align}\n",
    "H^T &= \\left(X(X^TX)^{-1}X^T\\right)^T\\\\\n",
    "&= X(X^TX)^{-T}X^T\\\\\n",
    "&= X(X^TX)^{-1}X^T\\\\\n",
    "&= H\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (b) We show that $H^2=H$ first.\n",
    "\n",
    "\\begin{align}\n",
    "H^2 &= \\left(X(X^TX)^{-1}X^T\\right)\\left(X(X^TX)^{-1}X^T\\right)\\\\\n",
    "&= X(X^TX)^{-1}(X^TX)(X^TX)^{-1}X^T\\\\\n",
    "&= X(X^TX)^{-1}X^T\\\\\n",
    "&= H\\\\\n",
    "\\end{align}\n",
    "\n",
    "Apply the above relationship repeatedly for $H^K$ we see that $H^K = H$.\n",
    "\n",
    "1. (c) First show $(I-H)^2=I-H$.\n",
    "\n",
    "\\begin{align}\n",
    "(I-H)^2 &= (I-H)(I-H)\\\\\n",
    "&= II - IH -HI + H^2\\\\\n",
    "&= I - 2H + H^2\\\\\n",
    "&= I-2H + H\\\\\n",
    "&= I-H\\\\\n",
    "\\end{align}\n",
    "\n",
    "Apply above relationship repeatedly for $(I-H)^K$, we have $(I-H)^K = I-H$.\n",
    "\n",
    "1. (d) Let $A=X(X^TX)^{-1}$, $B=X^T$, apply the property $\\text{trace}(AB)=\\text{trace}(BA)$, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\text{trace}(H) &= \\text{trace}\\left(X(X^TX)^{-1}X^T\\right)\\\\\n",
    "&= \\text{trace}\\left(AB\\right)\\\\\n",
    "&= \\text{trace}\\left(BA\\right)\\\\\n",
    "&=\\text{trace}\\left(X^TX(X^TX)^{-1}\\right)\\\\\n",
    "&=\\text{trace}\\left(I\\right)\\\\\n",
    "&= d+1\\\\\n",
    "\\end{align}\n",
    "\n",
    "where the identity matrix $I$ is of size $d+1$.\n",
    "\n",
    "#### Exercise 3.4\n",
    "\n",
    "1. (a) We have $y = Xw^{*}+\\epsilon$, take this into the expression for $\\hat{y}$, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} &= Hy\\\\\n",
    "&= H(Xw^{*} + \\epsilon)\\\\\n",
    "&= Hxw^{*} + H\\epsilon\\\\\n",
    "&= X(X^TX)^{-1}X^TXw^{*} + H\\epsilon\\\\\n",
    "&= Xw^{*} + H\\epsilon\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (b) \n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} -  y &= Xw^{*} + H\\epsilon - (Xw^{*} + \\epsilon)\\\\\n",
    "&= (H-I)\\epsilon\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (c) \n",
    "\n",
    "\\begin{align}\n",
    "E_{in}(w_{lin}) &= \\frac{1}{N}\\|Xw_{lin}-y\\|^2\\\\\n",
    "&= \\frac{1}{N}\\|y-\\hat{y}\\|^2\\\\\n",
    "&= \\frac{1}{N}\\|(I-H)\\epsilon\\|^2\\\\\n",
    "&= \\frac{1}{N}\\epsilon^T(I-H)^T(I-H)\\epsilon\\\\\n",
    "&= \\frac{1}{N}\\epsilon^T(I-H^T)(I-H)\\epsilon\\\\\n",
    "&= \\frac{1}{N}\\epsilon^T(I-H)(I-H)\\epsilon\\\\\n",
    "&= \\frac{1}{N}\\epsilon^T(I-H)\\epsilon\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (d)\n",
    "\n",
    "\\begin{align}\n",
    "E_{\\mathcal{D}}\\left[E_{in}(w_{lin})\\right] &= E_{\\mathcal{D}}\\left[\\frac{1}{N}\\epsilon^T(I-H)\\epsilon\\right]\\\\\n",
    "&= \\frac{1}{N}\\left(E_{\\mathcal{D}}[\\epsilon^T\\epsilon]-E_{\\mathcal{D}}[\\epsilon^TH\\epsilon]\\right)\\\\\n",
    "&= \\frac{1}{N}\\left(E_{\\mathcal{D}}[\\sum^N_{k=1}\\epsilon_k^2]-E_{\\mathcal{D}}[\\sum^N_{i=1}\\sum^N_{j=1}\\epsilon_ih_{ij}\\epsilon_j]\\right)\\\\\n",
    "&= \\frac{1}{N}\\left(\\sum^N_{k=1}E_{\\mathcal{D}}\\epsilon_k^2-\\sum^N_{i=1}\\sum^N_{j=1}E_{\\mathcal{D}}[\\epsilon_ih_{ij}\\epsilon_j]\\right)\\\\\n",
    "&= \\frac{1}{N}\\left(N\\sigma^2-\\sum^N_{i=1}E_{\\mathcal{D}}[\\epsilon_i^2h_{ii}]\\right)\\\\\n",
    "&= \\frac{1}{N}\\left(N\\sigma^2-\\sum^N_{i=1}h_{ii}E_{\\mathcal{D}}[\\epsilon_i^2]\\right)\\\\\n",
    "&= \\frac{1}{N}\\left(N\\sigma^2-\\sigma^2\\text{trace}(H)\\right)\\\\\n",
    "&= \\sigma^2\\left(1-\\frac{\\text{trace}(H)}{N}\\right)\\\\\n",
    "&= \\sigma^2\\left(1-\\frac{d+1}{N}\\right)\\\\\n",
    "\\end{align}\n",
    "\n",
    "Here we used the independence of $\\epsilon_i$, and also we assume $H$ is not random variable, so we are not doing expectation w.r.t. $x$, that's how we can pull $h_{ii}$ out of $E_{\\mathcal{D}}[\\epsilon_i^2h_{ii}]$.\n",
    "\n",
    "1. (e) Since $X$ doesn't change, only $\\epsilon$ changes, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} -  y^\\prime &= Xw^{*} + H\\epsilon - (Xw^{*} + \\epsilon^\\prime)\\\\\n",
    "&= H\\epsilon - \\epsilon^\\prime\\\\\n",
    "\\end{align}\n",
    "\n",
    "Following the procedure in problem (c) and (d), we have\n",
    "\n",
    "\\begin{align}\n",
    "E_{\\mathcal{D,\\epsilon^\\prime}}\\left[E_{test}(w_{lin})\\right] &= E_{\\mathcal{D},\\epsilon^\\prime}\\left[\\frac{1}{N}\\|y^\\prime - \\hat{y}\\|^2\\right]\\\\\n",
    "&= E_{\\mathcal{D},\\epsilon^\\prime}\\left[\\frac{1}{N}\\|\\epsilon^\\prime - H\\epsilon\\|^2\\right]\\\\\n",
    "&= \\frac{1}{N}E_{\\mathcal{D},\\epsilon^\\prime}\\left[(\\epsilon^\\prime - H\\epsilon)^T(\\epsilon^\\prime - H\\epsilon)\\right]\\\\\n",
    "&= \\frac{1}{N}E_{\\mathcal{D},\\epsilon^\\prime}\\left[(\\epsilon^{\\prime T} - \\epsilon^TH^T)(\\epsilon^\\prime - H\\epsilon)\\right]\\\\\n",
    "&= \\frac{1}{N}E_{\\mathcal{D},\\epsilon^\\prime}\\left[(\\epsilon^{\\prime T} - \\epsilon^TH)(\\epsilon^\\prime - H\\epsilon)\\right]\\\\\n",
    "&= \\frac{1}{N}E_{\\mathcal{D},\\epsilon^\\prime}\\left[\\epsilon^{\\prime T}\\epsilon^\\prime - \\epsilon^{\\prime T}H\\epsilon-\\epsilon^TH\\epsilon^\\prime + \\epsilon^THH\\epsilon\\right]\\\\\n",
    "&= \\frac{1}{N}E_{\\mathcal{D},\\epsilon^\\prime}\\left[\\epsilon^{\\prime T}\\epsilon^\\prime - \\epsilon^{\\prime T}H\\epsilon-\\epsilon^TH\\epsilon^\\prime + \\epsilon^TH\\epsilon\\right]\\\\\n",
    "&= \\frac{1}{N}E_{\\mathcal{D},\\epsilon^\\prime}\\left[\\epsilon^{\\prime T}\\epsilon^\\prime + \\epsilon^TH\\epsilon\\right]\\\\\n",
    "&= \\frac{1}{N}\\left(\\sum^N_{k=1}E_{\\mathcal{D}}\\epsilon_k^{\\prime 2} + \\sum^N_{i=1}\\sum^N_{j=1}E_{\\mathcal{D}}[\\epsilon_ih_{ij}\\epsilon_j]\\right)\\\\\n",
    "&= \\sigma^2\\left(1+\\frac{d+1}{N}\\right)\\\\\n",
    "\\end{align}\n",
    "\n",
    "Where we have used the fact that $\\epsilon$ and $\\epsilon^\\prime$ are independent of each other and each $\\epsilon_k$ and $\\epsilon_k^\\prime$ are independent among themselves. \n",
    "\n",
    "#### Exercise 3.5\n",
    "\n",
    "1. (a) \n",
    "\n",
    "\\begin{align}\n",
    "\\tanh(s) &= \\frac{e^s - e^{-s}}{e^s + e^{-s}}\\\\\n",
    "&= \\frac{e^{2s} - 1}{1+e^{2s}}\\\\\n",
    "&= \\theta(2s) - \\frac{1}{1+e^{2s}}\\\\\n",
    "&= \\theta(2s) - (1-\\theta(2s))\\\\\n",
    "&= 2\\theta(2s) - 1\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (b)\n",
    "\n",
    "\\begin{align}\n",
    "\\tanh(s) &= \\frac{e^s - e^{-s}}{e^s + e^{-s}}\\\\\n",
    "&= \\frac{1-e^{-2s}}{1+e^{-2s}}\\\\\n",
    "\\end{align}\n",
    "\n",
    "Let $s\\to \\infty$, we have $e^{-2s} \\to 0$, thus $\\tanh(s) \\to 1$.\n",
    "Similarly, when $s\\to -\\infty$, $\\tanh(s) \\to -1$.\n",
    "\n",
    "It's also easy to see that $\\tanh(s) \\lt 1$ and $\\tanh(s) \\gt -1$. So $-1$ and $1$ are hard thresholds for $\\tanh(s)$ when $|s|$ is large. \n",
    "\n",
    "When $|s|$ is small, consider Taylor expansion of $e^s = 1 + s + \\frac{s^2}{2}+O(s^3)$, then $e^{-s} = 1-s+\\frac{s^2}{2}-O(s^3)$, we have $\\tanh(s)=\\frac{e^s-e^{-s}}{e^s+e^{-s}} = \\frac{2s+2O(s^3)}{2+s^2} \\approx s$.\n",
    "\n",
    "So $\\tanh(s)$ is approximately linear when $|s|$ is small. There's no threshold in this case. \n",
    "\n",
    "#### Exercise 3.6\n",
    "\n",
    "1. (a) The probability to get $y_n$ is $P(y_n|x_n)$, by maximum likelihood method, we need maximize the likelihood, $\\prod^N_{n=1} P(y_n|x_n)$, this is equivalent to maximize the logrithm of it: $\\sum^N_{n=1}\\ln(P(y_n|x_n))$, or minimize the negative of it: $-\\sum^N_{n=1}\\ln(P(y_n|x_n))$\n",
    "\n",
    "When $y_n=+1$, $P(y_n|x_n)=h(x_n)$, and when $y_n=-1$, $P(y_n|x_n) = 1-h(x_n)$, separate the cases for $y_n=1$ and $y_n=-1$, we have:\n",
    "\n",
    "\\begin{align}\n",
    "E_{in}(w) &= -\\sum^N_{n=1}\\ln(P(y_n|x_n)) \\\\\n",
    "&= -\\sum^N_{n=1} I(y_n=+1)\\ln h(x_n) + I(y_n=-1)\\ln(1-h(x_n))\\\\\n",
    "&= \\sum^N_{n=1} I(y_n=+1)\\ln\\frac{1}{h(x_n)} + I(y_n=-1)\\ln\\frac{1}{(1-h(x_n))}\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (b) For $h(x) = \\theta(w^Tx) = \\frac{e^{w^Tx}}{1+e^{w^Tx}}$, we have $\\ln \\frac{1}{h(x_n)} = \\ln (1+e^{-w^Tx_n})$ and $\\ln \\frac{1}{(1-h(x_n))} = \\ln (1+e^{w^Tx_n})$. Combine them together we have\n",
    "\n",
    "\\begin{align}\n",
    "E_{in}(w) &= \\sum^N_{n=1} I(y_n=+1)\\ln (1+e^{-w^Tx_n}) + I(y_n=-1)\\ln (1+e^{w^Tx_n})\\\\\n",
    "&= \\sum^N_{n=1}\\ln (1+e^{-y_nw^Tx_n})\\\\\n",
    "\\end{align}\n",
    "\n",
    "Which is equivalent of minimizing the one in equation (3.9). \n",
    "\n",
    "\n",
    "#### Exercise 3.7\n",
    "\n",
    "Take derivative of $E_{in}(w) = \\frac{1}{N}\\sum^N_{n=1}\\ln (1+e^{-y_nw^Tx_n})$ with respect to $w$, we have: \n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla E_{in}(w) &= -\\frac{1}{N}\\sum^N_{n=1} \\frac{y_nx_n e^{-y_nw^Tx_n}}{1+e^{-y_nw^Tx_n}}\\\\\n",
    " &= -\\frac{1}{N}\\sum^N_{n=1} \\frac{y_nx_n }{1+e^{y_nw^Tx_n}}\\\\\n",
    "&= \\frac{1}{N}\\sum^N_{n=1} -y_nx_n \\theta(-y_nw^Tx_n)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "When a sample is misclassified, $y_nw^Tx_n \\lt 0$, so $\\theta(-y_nw^Tx_n) \\gt 0.5$, while when a sample is correctly classified, $\\theta(-y_nw^Tx_n) \\lt 0.5$, so the contribution of 'misclassified' example is more to the gradient than a correctly classified one. \n",
    "\n",
    "#### Exercise 3.8 \n",
    "\n",
    "$\\hat{v}$ is the direction which gives largest decrease in $E_{in}$ only holds for small $\\eta$, that's because when $\\eta$ is large, we can't ignore the squared term and smaller terms in the Taylor expansion. The lower bound can't be achieved.\n",
    "\n",
    "#### Exercise 3.9\n",
    "1. (a) See plot below\n",
    "1. (b) When $y = 1$\n",
    "  * If $s \\ge 0$, $e_{class}(s,y) = 0$, $e_{sq}(s,y) = (1-s)^2 \\ge 0$\n",
    "  * If $s \\lt 0$, $e_{class}(s,y) = 1$, $e_{sq}(s,y) = (1-s)^2 = 1 - 2s + s^2 \\gt 1$\n",
    "  \n",
    "  In both cases, we have $e_{sq}(s,y) \\ge e_{class}(s,y)$. \n",
    "Similarly, we can prove that when $y=-1$, we have $e_{sq}(s,y) \\ge e_{class}(s,y)$ as well.\n",
    "So $e_{sq}(s,y) \\ge e_{class}(s,y)$ for all cases of $s$ and $y$. The classification is upper bounded by the squared error. \n",
    "\n",
    "\n",
    "1. (c) When $y=1$, \n",
    "  * If $s \\ge 0$, $e_{class}(s,y) = 0$, $e_{log}(s,y) = \\ln(1+\\exp(-ys)) = \\ln(1+\\exp(-s)) \\ge \\ln1 = 0$, also $\\ln2 \\gt 0$, so we have $\\frac{1}{\\ln2}e_{log}(s,y) \\ge 0 = e_{class}(s,y)$.\n",
    "  * If $s \\lt 0$, $e_{class}(s,y) = 1$, $e_{log}(s,y) = \\ln(1+\\exp(-ys)) = \\ln(1+\\exp(-s)) \\gt \\ln2$, so $\\frac{1}{\\ln2}e_{log}(s,y) \\gt 1 = e_{class}(s,y)$\n",
    "  \n",
    "  Similaly, we can prove that when $y=-1$, we have $\\frac{1}{\\ln2}e_{log}(s,y) \\ge e_{class}(s,y)$ as well. \n",
    "The logistic regression is an upper bound to the classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tanh(s):\n",
    "    a = np.exp(s) - np.exp(-s)\n",
    "    b = np.exp(s) + np.exp(-s)\n",
    "    return a/b\n",
    "\n",
    "def classification_error(s, y):\n",
    "    signs = np.sign(s)\n",
    "    return signs != y\n",
    "\n",
    "def square_error(s, y):\n",
    "    return (y-s)**2\n",
    "\n",
    "def log_error(s, y):\n",
    "    return np.log(1.0+np.exp(-y*s))\n",
    "\n",
    "ss = np.arange(-10,10,0.1)\n",
    "cls_err = classification_error(ss, 1)\n",
    "sq_err = square_error(ss, 1)\n",
    "log_err = log_error(ss, 1)/np.log(2)\n",
    "plt.plot(ss, cls_err, label='Classification Error')\n",
    "plt.plot(ss, sq_err, label='Square Error')\n",
    "plt.plot(ss, log_err, label='Log Error')\n",
    "plt.ylim(-0.1, 2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.10\n",
    "\n",
    "1. (a) If $\\eta = 1$, then the SGD algorithm will update the $w$ by: $w(t+1) = w(t) -\\eta\\nabla e_n(w)  = w(t) -\\nabla e_n(w)$.\n",
    "\n",
    "When $e_n(w) = \\max(0, -y_n w^Tx_n)$, the derivative of $e_n(w)$ when $y_nw^Tx_n \\gt 0$ (when the sample is correctly classified) is zero, the derivative is $-y_nx_n$ when $y_nw^Tx_n \\lt 0$ (i.e. when the sample is misclassified). \n",
    "\n",
    "Take the derivatives into the SGD update equation, we see that's exactly PLA. \n",
    "\n",
    "1. (b) For logistic regression, we have $\\nabla e_n(w) = \\frac{-y_nx_n}{1+e^{y_nw^Tx_n}}$.\n",
    "If $w$ is very large:\n",
    "  * When $y_nw^Tx_n \\gt 0$, $\\nabla e_n(w) \\approx 0$.\n",
    "  * When $y_nw^Tx_n \\le 0$, $\\nabla e_n(w) \\approx -y_nx_n$. \n",
    "  \n",
    "The above results are consistent with the values used in PLA.\n",
    "\n",
    "This is another indication that the logistic regression weights can be used as a good approximation for classification. \n",
    "\n",
    "#### Exercise 3,.11\n",
    "\n",
    "Feature transformation $\\Phi(x) = (1, x^2_1, x^2_2)$, a hyperplane in $\\mathcal{Z}$ can be expressed as $\\tilde{w}z = \\tilde{w}_0 z_0 + \\tilde{w}_1 z_1 + \\tilde{w}_2 z_2 = \\tilde{w}_0 + \\tilde{w}_1 x^2_1 + \\tilde{w}_2 x^2_2 = 0$. \n",
    "1. (a) $|\\tilde{w}_1| x^2_1 - |\\tilde{w}_1| x^2_2 = c$ : Hyperbola\n",
    "\n",
    "1. (b) $\\tilde{w}_0 + \\tilde{w}_1 x^2_1= 0$: It can be two vertical lines parallel to axis of $x1$.\n",
    "\n",
    "1. (c) Ellipse.\n",
    "1. (d) No solution. For any $x_1$ and $x_2$, $\\tilde{w}z \\gt 0$. So we can't find $\\tilde{w}$ that satisfies the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
