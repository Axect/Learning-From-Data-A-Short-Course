{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame({'x1':[0,1,0,-0.5,-1,2,1,3,0.5,-1,0,-2,-3,1,2,-4,-3,3,-0.5,-2],\n",
    "                   'x2':[0,1,1,0,-1,4,-1,-5,-2,1,3,0,-1,6,8,2,3,10,2,1], \n",
    "                   'y':[1,1,1,1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1]})\n",
    "df['x0'] = 1\n",
    "df = df[['x0','x1', 'x2', 'y']]\n",
    "\n",
    "def perceptron(points, max_it=100):\n",
    "    w = np.zeros(3)\n",
    "    xs, ys = points[:,:3], points[:,3]\n",
    "    for it in range(max_it):\n",
    "        c = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            prod = np.dot(w.T, x)*y\n",
    "            if prod <= 0:\n",
    "                w = w + y*x\n",
    "            else:\n",
    "                c += 1\n",
    "        if c==20:\n",
    "            break\n",
    "    target = np.array([2,2,-1])\n",
    "    print('final correctness: ', c, '. Total iteration: ', it)\n",
    "    print('The true target: ', target, ' normalized target: ', target/np.sqrt(np.sum(np.square(target))))\n",
    "    print('Final hypothesis: ', w, ' normalized hypothesis: ', w/np.sqrt(np.sum(np.square(w))))\n",
    "    \n",
    "def flip_coins(total_coins):\n",
    "    \"\"\"Flip all coins once, return their head/tail status\n",
    "    \"\"\"\n",
    "    \n",
    "    hts = np.zeros(total_coins) #head: 1, tail: 0\n",
    "    probs = np.random.uniform(size=total_coins)\n",
    "    hts[probs > 0.5] = 1\n",
    "    return hts\n",
    "\n",
    "def run_once(total_coins, total_flips, print_freq = False):\n",
    "    v1, vrand, vmin = None, None, None\n",
    "    crand = np.random.choice(total_coins)\n",
    "    hts_sum = np.zeros(total_coins) # store the sum of heads in total_flips\n",
    "    \n",
    "    for flip in range(total_flips):\n",
    "        hts_sum = hts_sum + flip_coins(total_coins)\n",
    "    \n",
    "    hts_freq = hts_sum/total_flips\n",
    "    \n",
    "    v1 = hts_freq[0]\n",
    "    vrand = hts_freq[crand]\n",
    "    cmin = np.argmin(hts_sum)\n",
    "    vmin = hts_freq[cmin]\n",
    "    \n",
    "    if print_freq:\n",
    "        print('Frequency of first coin: {}'.format(v1))\n",
    "        print('Frequency of a random coin: id({})-freq({})'.format(crand, vrand))\n",
    "        print('Frequency of the coin with minimum frequency: id({})-freq({})'.format(cmin, vmin))\n",
    "    return v1,vrand,vmin\n",
    "\n",
    "def hoeffding_bound(epsilon, n):\n",
    "    return 2.0*np.exp(-2.0*n*epsilon**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 The Learning Problem\n",
    "\n",
    "## Exercises\n",
    "\n",
    "#### Exercise 1.1\n",
    "\n",
    "1. (a) \n",
    "  * Input space $\\mathcal{X}$: patient's medical history, symptoms, personal health information etc.\n",
    "  * Output space $\\mathcal{Y}$: all possible diseases\n",
    "  * target function $f: \\mathcal{X} \\to \\mathcal{Y}$: ideal formula to identify a patient's problem\n",
    "  * Data set: All available patients' information and their corresponding correct problem diagnostic.\n",
    "2. (b)\n",
    "  * Input space $\\mathcal{X}$: handwritten digits (digitalized)\n",
    "  * Output space $\\mathcal{Y}$: 0-9 digits\n",
    "  * target function $f: \\mathcal{X} \\to \\mathcal{Y}$: ideal formula match a handwritten digit to a correct digit\n",
    "  * Data set: handwritten digits and their corresponding correct matches\n",
    "3. (c)\n",
    "  * Input space $\\mathcal{X}$: every information of an email, e.g. words\n",
    "  * Output space $\\mathcal{Y}$: yes/no \n",
    "  * target function $f: \\mathcal{X} \\to \\mathcal{Y}$: ideal formula to identify whether an email is spam or not\n",
    "  * Data set: Spam and non-spam emails that have been identified by human\n",
    "4. (d)\n",
    "  * Input space $\\mathcal{X}$: price of electric, temperature, day of the week\n",
    "  * Output space $\\mathcal{Y}$: electric load\n",
    "  * target function $f: \\mathcal{X} \\to \\mathcal{Y}$: ideal function that gives exact electric load for a given price, temperature and day of the week.\n",
    "  * Data set: historical electric load along with corresponding price, temperature and day of the week information.\n",
    "5. (e) \n",
    "  * Input space $\\mathcal{X}$: cat images \n",
    "  * Output space $\\mathcal{Y}$: types of cats\n",
    "  * target function $f: \\mathcal{X} \\to \\mathcal{Y}$: ideal function that gives cat type according to the picture\n",
    "  * Data set: picutres with cats that have been categorized to various types\n",
    "\n",
    "#### Exercise 1.2\n",
    "1. (a) Keywords with a large positive weight: free, cheap, earn, !\n",
    "1. (b) Keywords with a negative weight: person name, hi, the\n",
    "1. (c) The parameter $b$ in perceptron directly affects how many borderline messages end up being classified as spam. This is because $b$ is the threshold used to classify the emails into spam and non-spam categories.\n",
    "\n",
    "#### Exercise 1.3\n",
    "1. (a) If $x(t)$ is misclassified by $w(t)$, then $w^T(t)x(t)$ has different signs of $y(t)$, thus $y(t)w^T(t)x(t) \\gt 0$.\n",
    "2. (b) \n",
    "\\begin{align}\n",
    "y(t)w^T(t+1)x(t)  &= y(t) \\left(w(t)+y(t)x(t)\\right)^Tx(t) \\\\\n",
    "&= y(t)\\left(w^T(t) + y(t)x^T(t)\\right)x(t) \\\\\n",
    "&= y(t)w^T(t)x(t) + y(t)y(t)x^T(t)x(t)\\\\\n",
    "&\\gt y(t)w^T(t)x(t) \\;\\;\\;\\text{because the last term is } \\ge \\text{ than } 0\\\\\n",
    "\\end{align}\n",
    "3. (c) \n",
    "\n",
    "From previous problem, we see that $y(t)w^T(t)x(t)$ is increasing with each update. \n",
    "\n",
    "If $y(t)$ is positive, but $w^T(t)x(t)$ is negative, we move $w^T(t)x(t)$ toward positive by increasing it. \n",
    "\n",
    "If however $y(t)$ is negative, but $w^T(t)x(t)$ is positive, $y(t)w^T(t)x(t)$ increases means $w^T(t)x(t)$ is decreasing, i.e. moving toward negative region. \n",
    "\n",
    "So the move from $w(t)$ to $w(t+1)$ is a move \"in the right direction\" as far as classifying $x(t)$ is concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4\n",
    "Implement the perceptron learning algorithm and check\n",
    "* Convergence speed: The convergence is fast, it only takes 9 iterations to find a solution.\n",
    "* How well the final hypothesis $g$ matches your target $f$: The final hypothesis $g$ doesn't match my target $f$ exactly, but they are pretty close as seen from their normalized vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final correctness:  20 . Total iteration:  9\n",
      "The true target:  [ 2  2 -1]  normalized target:  [ 0.66666667  0.66666667 -0.33333333]\n",
      "Final hypothesis:  [ 7.   7.5 -4. ]  normalized hypothesis:  [ 0.63570725  0.68111491 -0.36326129]\n"
     ]
    }
   ],
   "source": [
    "perceptron(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.5\n",
    "1. (a) Learning\n",
    "1. (b) Design\n",
    "1. (c) Learning\n",
    "1. (d) Design\n",
    "1. (e) Learning\n",
    "\n",
    "#### Exercise 1.6\n",
    "1. (a) Supervised Learning\n",
    "1. (b) Reinforcement Learning\n",
    "1. (c) Unsupervised Learning\n",
    "1. (d) Learning to play music\n",
    "  * If learn by yourself, it's unsupervised learning\n",
    "  * If learn from a teacher, it's supervised learning\n",
    "  * If learn by yourself but with someone to tell you if your music is good or not, it's reinforcement learning. \n",
    "1. (e) Supervised Learning\n",
    "\n",
    "#### Exercise 1.7\n",
    "1. (a) The learning algorithm will pick the final hypothesis that always returns 1. \n",
    "  * 1 out of 8 $f$ agrees with $g$ on all three points; 3 $f$ agree with $g$ on two of the points; 3 $f$ agree with $g$ on one of the points, 1 $f$ agrees with none of the points. \n",
    "1. (b) The learning algorithm will pick the final hypothesis that always returns 0. \n",
    "  * 1 out of 8 $f$ agrees with $g$ on all three points; 3 $f$ agree with $g$ on two of the points; 3 $f$ agree with $g$ on one of the points, 1 $f$ agrees with none of the points.\n",
    "1. (c) The learning algorithm will pick the final hypothesis $XOR$. \n",
    "  * 1 out of 8 $f$ agrees with $g$ on all three points; 3 $f$ agree with $g$ on two of the points; 3 $f$ agree with $g$ on one of the points, 1 $f$ agrees with none of the points.\n",
    "1. (d) The learning algorithm will pick the final hypothesis $f_7$. \n",
    "  * 1 out of 8 $f$ agrees with $g$ on all three points; 3 $f$ agree with $g$ on two of the points; 3 $f$ agree with $g$ on one of the points, 1 $f$ agrees with none of the points.\n",
    "  \n",
    "#### Exercise 1.8\n",
    "\n",
    "In a sample of 10 marbles, for the fraction $\\nu$ of red marbles to be $\\nu \\le 0.1$, we must have at most one red marbles. \n",
    "\n",
    "\\begin{align}\n",
    "P(number\\;of\\;red \\le 1) &= P(red = 0) + P(red = 1) \\\\\n",
    "&= (1-\\mu)^{10} + \\mu (1-\\mu)^9\\\\\n",
    "&= (1-\\mu)^9\\\\\n",
    "&= 1.0e-9\n",
    "\\end{align}\n",
    "\n",
    "#### Exercise 1.9\n",
    "We have $\\mu=0.9$, $N=10$, and want $\\nu \\le 0.1$, i.e. $|\\mu - \\nu| = \\mu - \\nu \\ge 0.9 - 0.1 = 0.8$. Let's pick $\\epsilon = 0.7$, then according to Hoeffding Inequity, we have\n",
    "\n",
    "\\begin{align}\n",
    "P(\\nu \\le 0.1) &= P(\\mu - \\nu \\ge 0.8)\\\\\n",
    "&= P(|\\mu - \\nu| \\ge 0.8) \\\\\n",
    "&\\le P(|\\mu - \\nu| \\gt 0.7) \\\\\n",
    "&= P(|\\mu - \\nu| \\gt \\epsilon) \\\\\n",
    "&\\le 2e^{-2\\epsilon^2N}\\\\\n",
    "&\\approx 0.0001109032\n",
    "\\end{align}\n",
    "\n",
    "This is an upper bound of the probability from pervious problem and is much larger than the calculated probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.10\n",
    "1. (a) The $\\mu$ for the three coins are all $0.5$ since the coins are fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of first coin: 0.5\n",
      "Frequency of a random coin: id(83)-freq(0.3)\n",
      "Frequency of the coin with minimum frequency: id(7)-freq(0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.3, 0.0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1.10 (a) \n",
    "total_coins = 1000\n",
    "total_flips = 10\n",
    "run_once(total_coins, total_flips, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.23941e+05, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        3.76049e+05, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+01]),\n",
       " array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:2369: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1.10 (b) \n",
    "total_coins = 1000\n",
    "total_flips = 10\n",
    "total_runs = 1000000\n",
    "v1s, vrands, vmins = [],[],[]\n",
    "for run in range(total_runs):\n",
    "    v1,vrand,vmin = run_once(total_coins, total_flips)\n",
    "    v1s.append(v1)\n",
    "    vrands.append(vrand)\n",
    "    vmins.append(vmin)\n",
    "\n",
    "fig, axs = plt.subplots(1,3,sharey=True, tight_layout=True)\n",
    "n_bins = 10\n",
    "axs[0].hist(v1s,bins=n_bins)\n",
    "axs[1].hist(vrands,bins=n_bins)\n",
    "axs[2].hist(vmins,bins=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x230e84aef98>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1.10 (c)\n",
    "eps = np.arange(0.0,0.5,0.05)\n",
    "bounds = hoeffding_bound(eps, total_flips)\n",
    "v1s, vrands, vmins = np.array(v1s), np.array(vrands), np.array(vmins)\n",
    "v1d = np.abs(v1s-0.5)\n",
    "vrandd = np.abs(vrands-0.5)\n",
    "vmind = np.abs(vmins-0.5)\n",
    "\n",
    "p1, prand, pmin = np.zeros(len(eps)),np.zeros(len(eps)),np.zeros(len(eps))\n",
    "\n",
    "for idx in range(eps.shape[0]):\n",
    "    ep = eps[idx]\n",
    "    p1[idx] = np.sum(v1d > ep)/total_runs\n",
    "    prand[idx] = np.sum(vrandd > ep)/total_runs\n",
    "    pmin[idx] = np.sum(vmind > ep)/total_runs\n",
    "\n",
    "#plt.ylim((0,0.01))    \n",
    "plt.plot(eps, bounds, marker='o', markerfacecolor='blue', markersize=8, color='skyblue', label='Hoeffding Bound')\n",
    "plt.plot(eps, p1, marker='', color='r', linewidth=1, label='First Coin')\n",
    "plt.plot(eps, prand, marker='', color='g', linewidth=1, linestyle='dashed', label='Random Coin')\n",
    "plt.plot(eps, pmin, marker='', color='y', linewidth=1, linestyle='dashed', label='Coin with Minimum Freq')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.10\n",
    "1. (d) The first and random coins follow the Hoeffding bound. The coin with minimum frequency doesn't obey Hoeffding bound. This is because that for the first two coins, the coins were chosen before the experiment. While for the last one, we have to flip all the coins first, and use the data to compute out which is the coin with minimum frequency of heads. This violates the Hoeffding inequality condition which says the hypothesis $h$ has been fixed before samples were drawn.\n",
    "\n",
    "1. (e) When we choose the coin having the minimum frequency of heads. We are like choosing the bin from 1000 bins (our hypothesis space). But we choose bin after we finish sampling the data.  This is akin to learning algorithm for the final hypothesis. The other two coins were chosen before the sampling, which is choosing bin beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.11\n",
    "\n",
    "1. (a) $S$ can not produce a hypothesis that is guaranteed to perform better than random on any point outside $\\mathcal{D}$. \n",
    "If $f$ has 25 $+1$ on $\\mathcal{D}$ but $-1$ on all other points in $\\mathcal{X}$, $S$ will choose the hypothesis $h_1$, which will not match $f$ outside of $\\mathcal{D}$ at all. On the other hand, a random function will have $+1$ and $-1$ 50/50, and it matches $f$ half of time, which is better than the function produced by $S$.\n",
    "\n",
    "1. (b) It is possible that $C$ produces a better hypothesis than $S$ produces. See the example above.\n",
    "1. (c) If every point in $\\mathcal{D}$ has 1, then $S$ will choose $h_1$ and $C$ will choose $h_2$. So outside of $\\mathcal{D}$, $h_1$ will have 90% chance to match with $f$, while $h_2$ will have only 10% chance. $S$ will always produce a better hypothesis than $C$. \n",
    "\n",
    "1. (d) From previous problem, we can see that when $p \\lt 0.5$, $C$ will produce a better hypothesis than $S$. Since $C$ always produce $h_2$, which will match $f$ better than $h_1$ if $p \\lt 0.5$.\n",
    "\n",
    "#### Exercise 1.12\n",
    "\n",
    "I think the best I can promise is (c). \n",
    "* The unknown target $f$ can be very complex that we can't learn at all.\n",
    "* If we can learn and produce a hypothesis $g$, since there are many data points (4000), the probability that $g$ matches $f$ is high according to Hoeffding inequality, and the error on $g$ might be small since we have a large data set.\n",
    "\n",
    "#### Exercise 1.13\n",
    "\n",
    "1. (a) The probability of error that $h$ makes in approximating $y$ is\n",
    "\n",
    "\\begin{align}\n",
    "P(h \\ne y) &= P(h \\ne y| y = f(x))P(y=f(x)) + P(h\\ne y| y \\ne f(x))P(y\\ne f(x))\\\\\n",
    "&= \\mu \\lambda + (1-\\mu)(1-\\lambda)\\\\\n",
    "&= \\mu (2 \\lambda - 1) + (1-\\lambda)\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (b) It can be seen from previous problem, that when $\\lambda = 0.5$, $P(h\\ne y) = 1-\\lambda = 0.5$, is independent of $\\mu$.\n",
    "\n",
    "## Problems\n",
    "\n",
    "#### Problem 1.1\n",
    "\n",
    "\\begin{align}\n",
    "P(1st \\;ball \\;is\\; black) &= P(1st\\; ball\\; is\\; black|picked\\; black,black\\; bag)P(picked\\; black,black\\; bag) + P(1st\\; ball\\; is\\; black|picked\\; black,white\\; bag)P(picked\\; black,white\\; bag)\\\\\n",
    "&= 1.0*0.5 + 0.5 * 0.5\\\\\n",
    "&= 0.75\\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "P(picked\\;black,black \\;bag|1st\\; ball\\; is\\; black) &= \\frac{P(picked\\; black,black\\; bag\\; and\\; 1st\\; ball\\; is\\; black)}{P(1st\\; ball\\; is\\; black)} \\\\\n",
    "&= \\frac{P(1st\\; ball\\; is\\; black|picked\\; black,black\\; bag)P(picked\\; black,black\\; bag)}{P(1st \\;ball \\;is\\; black)}\\\\\n",
    "&= \\frac{1.0*0.5}{0.75}\\\\\n",
    "&= \\frac{2}{3}\\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "P(picked\\;black,white \\;bag|1st\\; ball\\; is\\; black) &= \\frac{1}{3}\\\\\n",
    "\\end{align}\n",
    "\n",
    "Now we can compute the probability that the second ball is also black:\n",
    "\n",
    "\\begin{align}\n",
    "P(2nd\\; ball\\; is \\;black) &= P(2nd\\; ball\\; is\\; black|picked\\;black,black \\;bag|1st\\; ball\\; is\\; black)*P(picked\\;black,black \\;bag|1st\\; ball\\; is\\; black) + P(2nd\\; ball\\; is \\;black|picked\\;black,white \\;bag|1st\\; ball\\; is\\; black)*P(picked\\;black,white \\;bag|1st\\; ball\\; is\\; black)\\\\\n",
    "&= 1.0*\\frac{2}{3} + 0*\\frac{1}{3}\\\\\n",
    "&= \\frac{2}{3}\n",
    "\\end{align}\n",
    "\n",
    "#### Problem 1.2\n",
    "\n",
    "1. (a)\n",
    "\n",
    "for $h(x) =1$, we need to have $w^Tx \\gt 0$, and for $h(x) = -1$, we need to have $w^Tx \\lt 0$. The line separate the two regions has $w^Tx = w_0 + w_1 x_1 + w_2 x_2 = 0$, compare with $x_2 = ax_1 + b$, we have $ a = -\\frac{w_1}{w_2}$ and $b =  -\\frac{w_0}{w_2}$.\n",
    "\n",
    "1. (b) The pictures for the cases $w=[1,2,3]^T$ and $w=-[1,2,3]^T$ should be be same according to the formula above.\n",
    "\n",
    "#### Problem 1.3\n",
    "\n",
    "\n",
    "1. (a) If $w^{*}$ is the optimal set of weights that separate the data, then for every $x_n$ in the data set $\\mathcal{D}$, $w^{*T}x_n$ has the same sign as $y_n$, which means $y_n(w^{*T}x_n) \\gt 0$. This implies $\\rho = min_{1\\le n\\le N}y_n(w^{*T}x_n) \\gt 0$.\n",
    "\n",
    "\n",
    "1. (a) Let's use induction to prove this.\n",
    "  * When $t=1$, we have $w^T(t-1)w^* + \\rho = w^T(0)w^* + \\rho = \\rho$, while $w(t)=w(1) = w(0) + y_ix_i = y_ix_i$ for some $i$. \n",
    "  \n",
    "  So $w^T(t)w^* = (y_ix_i)^Tw^* = y_ix_i^Tw^* = y_iw^{*T}x_i$. Here we use the fact that $y_i \\in {-1,1}$ and $x_i^Tw^*$ is a scalar. By definition of $\\rho$, we have $y_iw^{*T}x_i \\ge \\rho$. Thus the inequation is valid at $t=1$.\n",
    "  \n",
    "  \n",
    "  * Suppose the inequation is valid at $t$, let's prove that it's still valid at $t+1$. \n",
    "  $w(t+1)=w(t)+y_ix_i$ for som e $i$. Then\n",
    "  \n",
    "  \\begin{align}\n",
    "  w^T (t+1)w^* &= w^T(t)w^* + y_ix_i^Tw^* \\\\\n",
    "  &\\ge w^T(t-1)w^* + \\rho + y_ix_i^Tw^*  \\\\\n",
    "  &= \\left(w^T(t-1) + y_ix_i^T\\right)w^* + \\rho \\\\\n",
    "  &= w^T(t)w^* + \\rho\n",
    "  \\end{align}\n",
    "  \n",
    "  This finishes the proof.\n",
    "  \n",
    "  It's easy to see that $w^T(t)w^* \\ge w^T(t-1)w^* + \\rho \\ge w^T(t-2)w^* + 2\\rho \\ge \\dots \\ge t\\rho$.\n",
    "  \n",
    "  \n",
    "1. (c) $w(t) = w(t-1) + y(t-1)x(t-1)$, take squared norm on $w(t)$ we have \n",
    "\n",
    "\\begin{align}\n",
    "||w(t)||^2 &= \\left(w(t-1) + y(t-1)x(t-1)\\right)^T\\left(w(t-1) + y(t-1)x(t-1)\\right)\\\\\n",
    "&= ||w(t-1)||^2 + ||y(t-1)||^2||x(t-1)||^2 + 2y(t-1)w^T(t-1)x(t-1) \\\\\n",
    "&= ||w(t-1)||^2 + ||x(t-1)||^2 + 2y(t-1)w^T(t-1)x(t-1) \\\\\n",
    "&\\le ||w(t-1)||^2 + ||x(t-1)||^2\n",
    "\\end{align}\n",
    "\n",
    "since $y(t-1)w^T(t-1)x(t-1) \\le 0$ because $x(t-1)$ was misclassified by $w(t-1)$.\n",
    "\n",
    "1. (d) Let's use induction.\n",
    "  * When $t=0$, it's obvious that $||w(0)||^2 = 0 \\le tR^2 = 0$.\n",
    "  * Assume at $t$, we have $||w(t)||^2 \\le tR^2$, then at $t+1$, we have $||w(t)||^2 \\le ||w(t-1)||^2 + ||x(t-1)||^2 $ from previous problem. Then we have\n",
    "  \n",
    "  $||w(t)||^2 \\le ||w(t-1)||^2 + ||x(t-1)||^2 \\le (t-1)R^2 + R^2 = tR^2$ \n",
    "  \n",
    "  where we used the fact that $||x(t-1)||^2 \\le R^2$ by definition of $R$.\n",
    "  \n",
    "1. (e) Apply the results from (b) and (d) we have \n",
    "\n",
    "$\\frac{w^T(t)}{||w(t)||} w^* \\ge \\frac{t\\rho}{||w(t)||} \\ge  \\frac{t\\rho}{\\sqrt{t}R} = \\sqrt{t}\\frac{\\rho}{R}$.\n",
    "\n",
    "\n",
    "Reverse the inequality and square, we have \n",
    "\n",
    "\\begin{align}\n",
    "t &\\le \\frac{R^2}{\\rho^2} \\frac{\\left(w^T(t)w^*\\right)^T\\left(w^T(t)w^*\\right)}{||w(t)||^2} \\\\\n",
    "&= \\frac{R^2}{\\rho^2} \\frac{w^{*T}w(t)w^T(t)w^*}{||w(t)||^2} \\\\\n",
    "&= \\frac{R^2}{\\rho^2} ||w^*||^2\n",
    "\\end{align}\n",
    "\n",
    "Or we can use the hint, where \n",
    "$\\frac{w^{*T}w^*}{||w(t)||||w^*||} \\le 1$ because $||w^T(t)w^*|| \\le ||w^T(t)||\\cdot||w^*||$ \n",
    "\n",
    "according to the Cauchy-Schwarz inequality. Then we have \n",
    "\n",
    "$\\sqrt{t}\\frac{\\rho}{R} \\le \\frac{w^{*T}w^*}{||w(t)||} \\le ||w^*||$\n",
    "\n",
    "Move $t$ to the right and square, we obtain the desired inequality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.4 TODO\n",
    "#### Problem 1.5 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.6\n",
    "\n",
    "1. (a) $P(\\nu=0) = (1-\\mu)^{10}$, so \n",
    "  * $P(\\nu = 0) =  0.5987369392383787$ when $\\mu = 0.05$\n",
    "  * $P(\\nu = 0) =  0.0009765625$ when $\\mu = 0.5$\n",
    "  * $P(\\nu = 0) =  1.0239999999999978e-07$ when $\\mu = 0.8$\n",
    "\n",
    "\n",
    "1. (b) We compute the probability that none of the 1000 samples have $\\nu = 0$, i.e. all samples have $\\nu \\gt 0$. For a given sample, we have $P(\\nu \\gt 0) = 1-P(\\nu = 0) = 1-(1-\\mu)^{10}$.  \n",
    "For all 1000 samples to have $\\nu \\gt 0$, the probability is \n",
    "\n",
    "$P(\\cap_{i=1}^{1000} \\nu_{i} \\gt 0) = \\prod_{i=1}^{1000}P(\\nu_i \\gt 0) = \\prod_{i=1}^{1000}[1-(1-\\mu)^{10}] =[1-(1-\\mu)^{10}]^{1000}$\n",
    "\n",
    "So the probability that at least one of the samples has $\\nu = 0$ is: $1-P(\\cap_{i=1}^{1000} \\nu_{i} \\gt 0) = 1-[1-(1-\\mu)^{10}]^{1000}$\n",
    "\n",
    "  * $P = 1$ when $\\mu = 0.05$\n",
    "  * $P = 0.623576201943276$ when $\\mu = 0.5$\n",
    "  * $P = 0.00010239476257623004$ when $\\mu = 0.8$\n",
    "\n",
    "1. (c) For 1000000 samples, we have the probability: $1-P(\\cap_{i=1}^{1000000} \\nu_{i} \\gt 0) = 1-[1-(1-\\mu)^{10}]^{1000000}$\n",
    "\n",
    "  * $P = 1$ when $\\mu = 0.05$\n",
    "  * $P = 1$ when $\\mu = 0.5$\n",
    "  * $P = 0.09733159268316072$ when $\\mu = 0.8$\n",
    "\n",
    "According to Hoeffding inequality, for given tolerance, the upper bound decreases with the number of samples. The probability of the deviation between $\\mu$ and $\\nu'$ (proportion of red marbles in samples) becomes smaller and smaller. So $\\nu'$ is closer to $\\mu$.\n",
    "\n",
    "#### Problem 1.7\n",
    "\n",
    "1. (a) Suppose there are $m$ coins, we compute the probability that none of the coins have $\\nu = 0$, i.e. all coins have $\\nu \\gt 0$. For a given coin, we have $P(\\nu \\gt 0) = 1-P(\\nu = 0) = 1-P[0|N,\\mu] = 1-(1-\\mu)^N$.  \n",
    "For all $m$ coins to have $\\nu \\gt 0$, the probability is \n",
    "\n",
    "$P(\\cap_{i=1}^{m} \\nu_{i} \\gt 0) = \\prod_{i=1}^{m}P(\\nu_i \\gt 0) = \\prod_{i=1}^{m}[1-(1-\\mu)^{N}] =[1-(1-\\mu)^{N}]^{m}$\n",
    "\n",
    "So the probability that at least one of the coins has $\\nu = 0$ is: $1-P(\\cap_{i=1}^{m} \\nu_{i} \\gt 0) = 1-[1-(1-\\mu)^{N}]^{m}$\n",
    "\n",
    "  * $P= 0.5987369392383787$ when $\\mu = 0.05, m = 1$\n",
    "  * $P= 1$ when $\\mu = 0.05, m = 1000$\n",
    "  * $P= 1$ when $\\mu = 0.05, m = 1000000$\n",
    "  \n",
    "  * $P= 1.02400000034919e-07$ when $\\mu = 0.8, m = 1$\n",
    "  * $P= 0.00010239476257623004$ when $\\mu = 0.8, m = 1000$\n",
    "  * $P= 0.09733159268316072$ when $\\mu = 0.8, m = 1000000$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. (b) TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.8 \n",
    "\n",
    "1. (a) Consider random variable $I(t\\ge \\alpha)$, which equals to $1$ when $t\\ge \\alpha$, else $0$. It's clear that for $\\alpha \\gt 0$ and $t$ a non-negative random variable, we have $\\alpha I(t \\ge \\alpha) \\le t$, take expectation on both sides, and since expectation is a monotonically increasing function here $(t \\ge 0)$ , we have \n",
    "\\begin{align}\n",
    "E[\\alpha I(t \\ge \\alpha)] &\\le E[t]\\\\\n",
    "\\alpha E[I(t \\ge \\alpha)] &\\le E[t]\\\\\n",
    "E[I(t \\ge \\alpha)] &\\le \\frac{E[t]}{\\alpha}\\\\\n",
    "P[t \\ge \\alpha] &\\le \\frac{E[t]}{\\alpha}\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (b) Since $(u-\\mu)^2 \\ge 0$, according to problem (a) above, for any $\\alpha \\gt 0$, we have $P[(u - \\mu)^2 \\ge \\alpha] \\le \\frac{E[(u-\\mu)^2]}{\\alpha} = \\frac{\\sigma^2}{\\alpha}$.\n",
    "\n",
    "1. (c) $u = \\frac{1}{N}\\sum_{n=1}^{N}$, this random variable has mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$. Take this into problem (b)'s inequation, we have $P[(u-\\mu)^2 \\ge \\alpha] \\le \\frac{\\sigma^2}{N\\alpha}$.\n",
    "\n",
    "This is the Chebyshev Inequality. Notice that the RHS goes down linearly in $N$, while the counterpart in Hoeffding's Inequality goes down exponentially. \n",
    "\n",
    "#### Problem 1.9\n",
    "\n",
    "1. (a) Consider random variable $I(t\\ge \\alpha)$, which equals to $1$ when $t\\ge \\alpha$, else $0$. It's clear that $e^{st}$ is monotonically increasing in $t$.We have $e^{\\alpha t} I(t \\ge \\alpha) \\le e^{st}$, take expectation on both sides, and since expectation is a monotonically increasing function here $(e^{st} \\ge 0)$ , we have \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E[e^{\\alpha t} I(t \\ge \\alpha)] &\\le E[e^{st}]\\\\\n",
    "e^{\\alpha t} E[I(t \\ge \\alpha)] &\\le E[e^{st}]\\\\\n",
    "E[I(t \\ge \\alpha)] &\\le e^{-\\alpha t}E[e^{st}]\\\\\n",
    "P[t \\ge \\alpha] &\\le e^{-\\alpha t}T(s)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "1. (b) Choose $t = uN$, and use $N\\alpha$ to replace $\\alpha$, according the previous problem, we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P[uN \\ge N\\alpha] &\\le e^{-sN\\alpha}E[e^{suN}]\\\\\n",
    "P[u \\ge \\alpha] &\\le e^{-sN\\alpha}E[e^{s\\sum_{n=1}^{N}u_n}]\\\\\n",
    "P[u \\ge \\alpha] &\\le e^{-sN\\alpha}E[\\prod_{n=1}^{N}e^{su_n}]\\\\\n",
    "P[u \\ge \\alpha] &\\le e^{-sN\\alpha}\\prod_{n=1}^{N}E[e^{su_n}]\\\\\n",
    "P[u \\ge \\alpha] &\\le e^{-sN\\alpha}E[e^{su_n}]^N\\\\\n",
    "P[u \\ge \\alpha] &\\le \\left(e^{-s\\alpha}U(s)\\right)^N\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "1. (c) $U(s) = E(e^{su_n}) = P(u_n=0)e^0 + P(u_n=1)e^s = \\frac{1}{2}(1+e^s)$, let's minimize $e^{-s\\alpha}U(s)$ by taking its derivative w.r.t. $s$ and let it equal to $0$, we have\n",
    "\n",
    "\\begin{align}\n",
    "-\\alpha e^{-s\\alpha}\\frac{1}{2}(1+e^s) + e^{-s\\alpha}\\frac{1}{2}e^s &= 0\\\\\n",
    "\\end{align}\n",
    "\n",
    "we conclude that $s = ln{\\frac{\\alpha}{1-\\alpha}}$ since $0 \\lt \\alpha \\lt 1$.\n",
    "\n",
    "1. (d) It's easy to see that $E[u] = \\frac{1}{2}$. Let $\\alpha = E(u) + \\epsilon = \\frac{1}{2} + \\epsilon$, then we have $P[u \\ge E(u) + \\epsilon] \\le (e^{-s\\alpha}U(s))^N$ from previous problem. Since this inequality holds for every $s \\gt 0$, it also holds for $s = ln{\\frac{\\alpha}{1-\\alpha}}$. Take this $s$ into the RHS of the inequality, we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "e^{-s\\alpha}U(s) &= e^{-s\\alpha} \\frac{1}{2}(1+e^s)\\\\\n",
    "&= \\frac{1}{2} e^{-\\alpha ln{\\frac{\\alpha}{1-\\alpha}}} (1+e^ {ln{\\frac{\\alpha}{1-\\alpha}}})\\\\\n",
    "&= \\frac{1}{2} \\left(\\frac{1-\\alpha}{\\alpha}\\right)^{\\alpha} (1+\\frac{\\alpha}{1-\\alpha})\\\\\n",
    "&= \\frac{1}{2} \\left(\\frac{1-\\alpha}{\\alpha}\\right)^{\\alpha} \\frac{1}{1-\\alpha}\\\\\n",
    "&= \\frac{1}{2} \\frac{(1-\\alpha)^{\\alpha -1}}{\\alpha^{\\alpha}}\\\\\n",
    "&= \\frac{1}{2} \\frac{(\\frac{1}{2}-\\epsilon)^{\\epsilon -\\frac{1}{2}}}{(\\frac{1}{2}+\\epsilon)^{\\frac{1}{2}+\\epsilon}}\\\\\n",
    "&= \\frac{1}{2}(\\frac{1}{2}-\\epsilon)^{-(\\frac{1}{2}-\\epsilon)}(\\frac{1}{2}+\\epsilon)^{-(\\frac{1}{2}+\\epsilon)}\\\\\n",
    "&= 2^{-\\beta}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\beta = 1 + (\\frac{1}{2}+\\epsilon)log_2{(\\frac{1}{2}+\\epsilon)}+ (\\frac{1}{2}-\\epsilon)log_2{(\\frac{1}{2}-\\epsilon)}$\n",
    "\n",
    "This proves that $P[u \\ge E(u) + \\epsilon] \\le 2^{-\\beta N}$.\n",
    "\n",
    "We now prove that $\\beta \\gt 0$. To prove that $\\beta \\gt 0$, we first prove that $\\beta$ is mononically increasing, then we find its minimum at $\\epsilon = 0$. \n",
    "\n",
    "Take derivative of $\\beta$ with respect to $\\epsilon$, we have \n",
    "\\begin{align}\n",
    "\\frac{\\partial{\\beta}}{\\partial{\\epsilon}} &= log_2{(\\frac{1}{2}+\\epsilon)} + 1 - log_2{(\\frac{1}{2}-\\epsilon)} - 1\\\\\n",
    "&= log_2{(\\frac{1}{2}+\\epsilon)} - log_2{(\\frac{1}{2}-\\epsilon)}\\\\\n",
    "\\end{align}\n",
    "\n",
    "The derivative is always larger or equal to zero, so $\\beta$ is mononically increasing function. It thus achieves minimum at left point, $\\epsilon=0$, where $\\beta=0$. \n",
    "So we have proved that $\\beta \\gt 0$, since $0 \\lt \\epsilon \\lt \\frac{1}{2}$. hence the bound is exponentially decreasing in $N$.\n",
    "\n",
    "#### Problem 1.10\n",
    "\n",
    "1. (a) $E_{off}(h,f)$ equals to the fraction of odd numbers between $N+1$ and $N+M$ in total $M$ numbers.\n",
    "\n",
    "1. (b) For a function $f$ to generate $\\mathcal{D}$ in a noiseless setting, it means $f(x_i)=y_i$ for $i=1,2,\\dots, N$. They only have freedom to assign various values on the rest points in $\\mathcal{X}$, i.e. $x_{N+1},\\dots,x_{N+M}$. So there are total $2^M$ $f$ that can generate $\\mathcal{D}$.\n",
    "\n",
    "1. (c) Among those $f$ in(b), if they agree with a given $h$ on $M-k$ points, i.e. $E_{off}(h,f)=\\frac{k}{M}$, then each of them need to choose $k$ points from $M$ $x_{N+1},\\dots,x_{N+M}$ to match with $y$, and other $M-k$ points to mismatch with $y$.\n",
    "This has ${M \\choose k}$ combinations.\n",
    "\n",
    "1. (d) TODO\n",
    "\n",
    "1. (e) TODO\n",
    "\n",
    "#### Problem 1.11\n",
    "\n",
    "Let the risk to be $r_{1}$ when $y_n=1$ and $r_{-1}$ when $y_n = -1$. The in-sample error $E_{in} = \\sum_{i=1}^{N} max\\left( -h(x_i)y_i,0\\right)r(y_i) = \\sum_{i=1}^{N} max\\left( -h(x_i)y_i,0\\right) [max(y_i,0), max(-y_i,0)] \\cdot [r_1, r_{-1}]^T $\n",
    "\n",
    "#### Problem 1.12\n",
    "\n",
    "1. (a) Take derivative of $E_{in}(h)$ w.r.t. $h$, and let it equal to $0$, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial{E_{in}(h)}}{\\partial{h}} &= \\sum_{n=1}^{N}2(h-y_n) \\\\\n",
    "h_{mean} &= \\frac{1}{N} \\sum_{n=1}^{N}y_n\\\\\n",
    "\\end{align}\n",
    "\n",
    "1. (b) Take derivative of $E_{in}(h)$ w.r.t. $h$, and let it equal to $0$, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial{E_{in}(h)}}{\\partial{h}} &= \\sum_{n=1}^{N}sign(h - y_n) \\\\\n",
    "\\end{align}\n",
    "\n",
    "It's clear, that $h_{med}$ (which is any value for which half the data points are at most $h_{med}$ and half the data points are at least $h_{med}$) will make the derivative to zero, thus minimize the in-sample error.\n",
    "\n",
    "1. (c) If $y_N$ is perturbed to $y_N + \\epsilon$, where $\\epsilon \\to \\infty$, we can see that $h_{mean}$ will increase a lot since $y_N$ contributes to its calculation, but $h_{med}$ can stay the same, because it only requires $h_{med} \\lt y_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
