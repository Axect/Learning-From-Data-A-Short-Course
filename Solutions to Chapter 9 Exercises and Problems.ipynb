{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lib input sys.path\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "from functools import partial\n",
    "import h5py\n",
    "from scipy.spatial import distance\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import libs.linear_models as lm\n",
    "import libs.data_util as data\n",
    "import libs.nn as nn\n",
    "import libs.plot as myplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9.1\n",
    "\n",
    "$x_g = (47,35)$, $x_b = (22, 40)$, $x_u = (21, 36)$\n",
    "\n",
    "The distance from $x_u$ to Mr. Bad is closer than the distance to Mr. Good. So the BoL should NOT give hime credit.\n",
    "\n",
    "If the income is measured in dollars, Mr. Unknown is closer to Mr. Good, so the BoL should give him credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Income measured in K\n",
      "--- Distance from unknow to Mr. Good: 26.019223662515376\n",
      "--- Distance from unknow to Mr. Bad: 4.123105625617661\n",
      "--- Income measured in dollars\n",
      "--- Distance from unknow to Mr. Good: 1000.3379428972991\n",
      "--- Distance from unknow to Mr. Bad: 4000.000124999998\n"
     ]
    }
   ],
   "source": [
    "# The distance between $x_u$ and the two points\n",
    "print('--- Income measured in K')\n",
    "xg = np.array([47, 35])\n",
    "xb = np.array([22, 40])\n",
    "xu = np.array([21, 36])\n",
    "\n",
    "d_ug = np.linalg.norm(xu-xg)\n",
    "d_ub = np.linalg.norm(xu-xb)\n",
    "print(f\"--- Distance from unknow to Mr. Good: {d_ug}\")\n",
    "print(f\"--- Distance from unknow to Mr. Bad: {d_ub}\")\n",
    "\n",
    "print('--- Income measured in dollars')\n",
    "# Income measured in dollars\n",
    "xg = np.array([47, 35000])\n",
    "xb = np.array([22, 40000])\n",
    "xu = np.array([21, 36000])\n",
    "\n",
    "d_ug = np.linalg.norm(xu-xg)\n",
    "d_ub = np.linalg.norm(xu-xb)\n",
    "print(f\"--- Distance from unknow to Mr. Good: {d_ug}\")\n",
    "print(f\"--- Distance from unknow to Mr. Bad: {d_ub}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9.2\n",
    "\n",
    "\\begin{align*}\n",
    "Z &= \\gamma X \\\\\n",
    "&= (I - \\frac{1}{N}1 1^T)X \\\\\n",
    "&= X - \\frac{1}{N} 1 1^T X\\\\\n",
    "&= X - 1\\frac{1}{N} \\begin{bmatrix}\\sum^N_{i=1} x_{i1} & \\sum^N_{i=1} x_{i2} & \\dots & \\sum^N_{i=1} x_{id}\\end{bmatrix}  \\\\\n",
    "&= X - 1\\begin{bmatrix}\\bar{x}_1 & \\bar{x}_2 & \\dots & \\bar{x}_d\\end{bmatrix}\\\\\n",
    "&=  X - 1\\bar{x}^T \\\\\n",
    "\\end{align*}\n",
    "\n",
    "#### Exercise 9.3\n",
    "\n",
    "\\begin{align*}\n",
    "Z &= \\begin{bmatrix}z^T_1 \\\\ \\dots \\\\ z^T_N \\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}(Dx_1)^T \\\\ \\dots \\\\ (Dx_N)^T\\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}x_1^TD^T \\\\ \\dots \\\\ x_N^TD^T \\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}x_1^TD \\\\ \\dots \\\\ x_N^TD \\end{bmatrix}\\\\\n",
    "&= XD \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "Z^TZ &= (XD)^TXD \\\\\n",
    "&= D^TX^TXD\\\\\n",
    "&= DX^TXD\\\\\n",
    "\\end{align*}\n",
    "\n",
    "#### Exercise 9.4\n",
    "\n",
    "* (a) $\\text{variance}(x_1) = \\text{variance}(\\hat{x}_1) = 1$, $\\text{variance}(x_2) = \\text{variance}(\\sqrt{1-\\epsilon^2}\\hat{x}_1+\\epsilon\\hat{x}_2) = (1-\\epsilon^2)\\text{variance}(\\hat{x}_1)+ \\epsilon^2 \\text{variance}(\\hat{x}_2) = 1$\n",
    "\n",
    "$\\text{covariance}(x_1,x_2) = E[(x_1 - \\bar{x}_1)(x_2 - \\bar{x}_2)] = E[x_1x_2] = E[\\sqrt{1-\\epsilon^2}\\hat{x}^2_1 + \\epsilon\\hat{x}_1\\hat{x}_2] = \\sqrt{1-\\epsilon^2}$\n",
    "\n",
    "* (b) \n",
    "\n",
    "\\begin{align*}\n",
    "f(x) &= w_1x_1 + w_2x_2 \\\\\n",
    "&= w_1\\hat{x}_1 + w_2 (\\sqrt{1-\\epsilon^2}\\hat{x}_1 + \\epsilon \\hat{x}_2) \\\\\n",
    "&= (w_1 + w_2 \\sqrt{1-\\epsilon^2})\\hat{x}_1 + w_2\\epsilon \\hat{x}_2 \\\\\n",
    "&= \\hat{w}_1\\hat{x}_1 + \\hat{w}_2 \\hat{x}_2 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "So if we set $\\hat{w}_1 = w_1 + w_2 \\sqrt{1-\\epsilon^2}, \\hat{w}_2 = w_2\\epsilon$, we see $f$ is linear in $x_1,x_2$.\n",
    "\n",
    "* (c) From problem (b), we have $\\hat{w}_1 = \\hat{w}_2 = 1$, so we have $w_1 = \\frac{\\epsilon - \\sqrt{1-\\epsilon^2}}{\\epsilon}, w_2 = \\frac{1}{\\epsilon}$, so that $C \\ge w^2_1 + w^2_2 = 2\\frac{1-\\epsilon\\sqrt{1-\\epsilon^2}}{\\epsilon^2}$\n",
    "\n",
    "* (d) As $\\epsilon \\to 0$, we have the minimum $C \\to \\infty $. It means that we have to use a huge $C$ to be able to implement the target function, which is impossible here.\n",
    "\n",
    "* (e) If there is significant noise in the data, with correlated inputs, it'll be hard to regularize the learning, and overfitting is likely. So var term can be high while bias can be low.\n",
    "\n",
    "#### Exercise 9.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
